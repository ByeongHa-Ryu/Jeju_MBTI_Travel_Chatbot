from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain.agents.agent_types import AgentType
from langchain_core.output_parsers import StrOutputParser,JsonOutputParser
from langchain.memory import ConversationBufferMemory
from langchain_google_genai import GoogleGenerativeAI # type: ignore
from langchain.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.runnables import ConfigurableField

from dotenv import load_dotenv
import os
from prompts import cls_llm_inst
import pandas as pd
from prompts import * 
import streamlit as st
from transformers import AutoTokenizer, AutoModel
import numpy as np 

import folium
from folium import plugins
import streamlit as st
from streamlit_folium import st_folium
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

import streamlit as st
import folium
from streamlit_folium import st_folium
import pandas as pd
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
import numpy as np
from geopy.distance import geodesic


"""LLM Blocks"""

def mbti_month(mbti, month):
    mbti = mbti
    month = month

load_dotenv()
my_api_key = os.getenv("GOOGLE_API_KEY")

## LLM call 
llm = GoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=my_api_key)

## dataframe agent 
data_dir = 'database/JEJU_MCT_DATA_final.csv'
df = pd.read_csv(data_dir)

## Data Frame agent on Gemini Engine 
agent = create_pandas_dataframe_agent(
    llm=llm,                           
    df=df,                             
    verbose=True,                      
    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, 
    output_parser=StrOutputParser(),
    prompt=agent_inst,
    allow_dangerous_code=True 
)

def validate_mbti(mbti):
    if len(mbti) != 4:
        return False
    
    valid_pairs = {
        0: {"E", "I"},
        1: {"N", "S"},
        2: {"F", "T"},
        3: {"P", "J"}
    }
    
    return all(mbti[i] in valid_pairs[i] for i in range(4))

def clear_chat_history():
    st.session_state.memory = ConversationBufferMemory()
    st.session_state.messages = [{"role": "assistant", "content": "ì œì£¼ë„ë¥¼ ì—¬í–‰í•˜ê¸° ë”± ì¢‹ì€ ë‚ ì”¨ë„¤ìš” ğŸ˜"}]

def load_df(mbti, month):
    model_name = "upskyy/bge-m3-Korean"
    model_kwargs = {'device': 'cpu'}
    embeddings = HuggingFaceEmbeddings(
        model_name=model_name,
        model_kwargs=model_kwargs
    )

    loaded_db = FAISS.load_local(
        folder_path=f"./database/mct_db/{mbti}/{month}",
        index_name=f"mct_{mbti}_{month}",
        embeddings=embeddings,
        allow_dangerous_deserialization=True,
    )

    return loaded_db

def retrieve_mct(loaded_db, query):
   retriever = loaded_db.as_retriever(
       search_type="mmr", 
       search_kwargs={
           "k": 3,
           "fetch_k": 20,
           "lambda_mult": 0.8
       }
   )
   query = f"{query} {st.session_state.get('mbti', '')}"
   return retriever.get_relevant_documents(query)

def load_faiss_and_search(query, mbti, month, k=3,):
    try:
        loaded_db = load_df(mbti, month)
        retrieve_documents = retrieve_mct(loaded_db, query)

        search_results = []
        for doc in retrieve_documents:
            metadata = doc.metadata
 
            try:
                search_results.append({
                    'index': metadata['idx'],
                    'ìœ„ë„': float(metadata['ìœ„ë„']) if pd.notna(metadata['ìœ„ë„']) else np.nan,
                    'ê²½ë„': float(metadata['ê²½ë„']) if pd.notna(metadata['ê²½ë„']) else np.nan,
                })
            except (ValueError, TypeError):
                search_results.append({
                    'index': metadata['idx'],
                    'ìœ„ë„': np.nan,
                    'ê²½ë„': np.nan,
                })

        return search_results
        
    except Exception as e:
        st.error(f"FAISS ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def get_restaurant_details(search_results, restaurants_df):
    try:
        restaurants_data = []
        for result in search_results:
            # Fixed: Added idx key access
            if 'index' in result: # ì¬ë°©ë¬¸ë¥ 
                restaurant = restaurants_df.iloc[result['index']]
                restaurants_data.append({
                    'ìŒì‹ì ëª…': restaurant['ê°€ë§¹ì ëª…'],
                    'ì£¼ì†Œ': restaurant['ì£¼ì†Œ'],
                    'ì—…ì¢…': restaurant['ì—…ì¢…'],
                    'ìœ„ë„': result['ìœ„ë„'],
                    'ê²½ë„': result['ê²½ë„'],
                })
        return pd.DataFrame(restaurants_data)

    except Exception as e:
        st.error(f"ìŒì‹ì  ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def find_nearby_tourist_spots(restaurant_row, tourist_spots_df, n=3):
    try:
        if pd.isna(restaurant_row['ìœ„ë„']) or pd.isna(restaurant_row['ê²½ë„']):
            return []

        restaurant_coords = (restaurant_row['ìœ„ë„'], restaurant_row['ê²½ë„'])
        distances = []
        
        for _, tourist in tourist_spots_df.iterrows():
            if pd.isna(tourist['ìœ„ë„']) or pd.isna(tourist['ê²½ë„']):
                continue
                
            try:
                tourist_coords = (tourist['ìœ„ë„'], tourist['ê²½ë„'])
                distance = geodesic(restaurant_coords, tourist_coords).kilometers
                
                distances.append({
                    'ê´€ê´‘ì§€ëª…': tourist['ê´€ê´‘ì§€ëª…'],
                    'ì£¼ì†Œ': tourist['ì£¼ì†Œ'],
                    'ëŒ€ë¶„ë¥˜': tourist['ëŒ€ë¶„ë¥˜'],
                    'ì¤‘ë¶„ë¥˜': tourist['ì¤‘ë¶„ë¥˜'],
                    'ì†Œë¶„ë¥˜': tourist['ì†Œë¶„ë¥˜'],
                    'ìœ„ë„': tourist['ìœ„ë„'],
                    'ê²½ë„': tourist['ê²½ë„'],
                    'ê±°ë¦¬': distance
                })
            except Exception as e:
                print(f"ê±°ë¦¬ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ê´€ê´‘ì§€: {tourist['ê´€ê´‘ì§€ëª…']}): {str(e)}")
                continue
        return sorted(distances, key=lambda x: x['ê±°ë¦¬'])[:n] if distances else []
        
    except Exception as e:
        st.error(f"ê´€ê´‘ì§€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def create_map_with_restaurants_and_tourists(restaurants_df, tourist_spots):
    try:
        if restaurants_df is None or restaurants_df.empty:
            st.warning("ë§›ì§‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        valid_locations = restaurants_df[restaurants_df['ìœ„ë„'].notna() & restaurants_df['ê²½ë„'].notna()]
        if valid_locations.empty:
            st.warning("ìœ íš¨í•œ ìœ„ì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        center_lat = valid_locations.iloc[0]['ìœ„ë„']
        center_lng = valid_locations.iloc[0]['ê²½ë„']
        
        m = folium.Map(
            location=[center_lat, center_lng],
            zoom_start=14,
            tiles='CartoDB positron',
            width=800,
            height=600
        )
        
        for idx, row in restaurants_df.iterrows():
            if pd.isna(row['ìœ„ë„']) or pd.isna(row['ê²½ë„']):
                continue
                
            popup_content = f"""
                <div style='width: 200px'>
                    <h4 style='margin: 0; padding: 5px 0;'>{row['ìŒì‹ì ëª…']}</h4>
                    <p style='margin: 5px 0;'>ì£¼ì†Œ: {row['ì£¼ì†Œ']}</p>
                </div>
            """
            
            folium.Marker(
                location=[row['ìœ„ë„'], row['ê²½ë„']],
                popup=folium.Popup(popup_content, max_width=300),
                icon=folium.Icon(color='red', icon='info-sign')
            ).add_to(m)
            
            if idx < len(tourist_spots):
                for tourist in tourist_spots[idx]:
                    if pd.isna(tourist['ìœ„ë„']) or pd.isna(tourist['ê²½ë„']):
                        continue
                        
                    tourist_popup = f"""
                        <div style='width: 200px'>
                            <h4 style='margin: 0; padding: 5px 0;'>{tourist['ê´€ê´‘ì§€ëª…']}</h4>
                            <p style='margin: 5px 0;'>ì£¼ì†Œ: {tourist['ì£¼ì†Œ']}</p>
                        </div>
                    """
                    
                    folium.Marker(
                        location=[tourist['ìœ„ë„'], tourist['ê²½ë„']],
                        popup=folium.Popup(tourist_popup, max_width=300),
                        icon=folium.Icon(color='blue', icon='info-sign')
                    ).add_to(m)
        
        return m
        
    except Exception as e:
        st.error(f"ì§€ë„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def display_map_with_data(map_obj):
    try:
        if map_obj:
            if 'map_container' not in st.session_state:
                st.session_state.map_container = st.empty()
                
            with st.session_state.map_container:
                st_folium(
                    map_obj,
                    width=700,
                    height=500,
                    key="persistent_map",
                    returned_objects=[]
                )
                
    except Exception as e:
        st.error(f"ì§€ë„ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@st.cache_data
def create_cached_map(_restaurants_data, _tourist_spots):
    return create_map_with_restaurants_and_tourists(_restaurants_data, _tourist_spots)

def format_restaurant_and_tourist_response(restaurants_df, tourist_spots):
    try:
        if restaurants_df is None or restaurants_df.empty:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë§›ì§‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        formatted_data = []
        for idx, row in restaurants_df.iterrows():
            restaurant_info = {
                "ì´ë¦„": row['ìŒì‹ì ëª…'],
                "ì—…ì¢…": row['ì—…ì¢…'],
                "ì£¼ì†Œ": row['ì£¼ì†Œ'],
                "ì£¼ë³€_ê´€ê´‘ì§€": [
                    {
                        "ì´ë¦„": tourist['ê´€ê´‘ì§€ëª…'],
                        "ì£¼ì†Œ": tourist['ì£¼ì†Œ'],
                        "ëŒ€ë¶„ë¥˜": tourist['ëŒ€ë¶„ë¥˜'],
                        "ì¤‘ë¶„ë¥˜": tourist['ì¤‘ë¶„ë¥˜'],
                        "ì†Œë¶„ë¥˜": tourist['ì†Œë¶„ë¥˜'],
                        "ê±°ë¦¬": f"{tourist['ê±°ë¦¬']:.1f}km"
                    }
                    for tourist in tourist_spots[idx]
                ]
            }
            formatted_data.append(restaurant_info)
            
        return formatted_data
        
    except Exception as e:
        return f"ì •ë³´ í¬ë§¤íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def generate_llm_response(query, formatted_data, user_mbti=None):
    try:
        prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: {query}

        ì•„ë˜ëŠ” ê²€ìƒ‰ëœ ë§›ì§‘ê³¼ ì£¼ë³€ ê´€ê´‘ì§€ ì •ë³´ì…ë‹ˆë‹¤:
        {formatted_data}

        {f'ì‚¬ìš©ìì˜ MBTIëŠ” {user_mbti}ì…ë‹ˆë‹¤.' if user_mbti else ''}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ìì—°ìŠ¤ëŸ¬ìš´ ë§›ì§‘ê³¼ ê´€ê´‘ì§€ ì¶”ì²œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

        1. ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í†¤ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        2. ê° ë§›ì§‘ì˜ ì¥ì ê³¼ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        3. ê° ë§›ì§‘ ê·¼ì²˜ì˜ ê´€ê´‘ì§€ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì†Œê°œí•´ì£¼ì„¸ìš”.
        4. ë§›ì§‘ê³¼ ê´€ê´‘ì§€ì˜ ìœ„ì¹˜ì  íŠ¹ì„±ì´ë‚˜ ì ‘ê·¼ì„±ì— ëŒ€í•´ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
        5. ì‚¬ìš©ìì˜ MBTIê°€ ìˆë‹¤ë©´, ê·¸ì— ë§ì¶˜ ì„¤ëª…ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.
        6. ë§›ì§‘ê³¼ ê´€ê´‘ì§€ë¥¼ í•¨ê»˜ ì¦ê¸°ëŠ” ì½”ìŠ¤ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.
        7. ì¦ê±°ìš´ ì—¬í–‰ì´ ë˜ê¸¸ ë°”ë¼ëŠ” ë©˜íŠ¸ë¡œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.

        ë‹µë³€ì—ì„œëŠ” ìœ„ë„/ê²½ë„ ì •ë³´ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”."""

        return llm.invoke(input=prompt)
        
    except Exception as e:
        return f"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ì±—ë´‡ ì½”ë“œ ìˆ˜ì •
def process_recommendation(message, mbti, month):
   try:
       restaurants_df = pd.read_csv(f"./database/mct_df/{mbti}/mct_{month}_{mbti}.csv")
       tourist_spots_df = pd.read_csv(f"./database/tour_df/{mbti}/tour_{month}_{mbti}.csv")
       
       search_results = load_faiss_and_search(message, mbti, month, k=3)
       if not search_results:
           return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹í•˜ëŠ” ë§›ì§‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None, None
           
       restaurants_data = get_restaurant_details(search_results, restaurants_df)
       if restaurants_data is None:
           return "ìŒì‹ì  ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", None, None
           
       tourist_spots = []
       for _, restaurant in restaurants_data.iterrows():
           nearby_spots = find_nearby_tourist_spots(restaurant, tourist_spots_df)
           tourist_spots.append(nearby_spots)

       # ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ëˆ„ì  ì €ì¥
       if 'all_restaurants' not in st.session_state:
           st.session_state.all_restaurants = restaurants_data
       else:
           st.session_state.all_restaurants = pd.concat([st.session_state.all_restaurants, restaurants_data], ignore_index=True)
           
       if 'all_tourist_spots' not in st.session_state:
           st.session_state.all_tourist_spots = tourist_spots
       else:
           st.session_state.all_tourist_spots.extend(tourist_spots)
           
       formatted_data = format_restaurant_and_tourist_response(restaurants_data, tourist_spots)
       
       user_mbti = st.session_state.get('mbti', None)
       response = generate_llm_response(message, formatted_data, user_mbti)
       
       return response, restaurants_data, tourist_spots
       
   except Exception as e:
       print(f"Error in recommendation process: {e}")
       return f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", None, None