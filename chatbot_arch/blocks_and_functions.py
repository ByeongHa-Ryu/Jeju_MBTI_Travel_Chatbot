from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain.agents.agent_types import AgentType
from langchain_core.output_parsers import StrOutputParser,JsonOutputParser
from langchain.memory import ConversationBufferMemory
from langchain_google_genai import GoogleGenerativeAI # type: ignore
from dotenv import load_dotenv
import os
from prompts import cls_llm_inst
import pandas as pd
from prompts import * 
import streamlit as st
from transformers import AutoTokenizer, AutoModel
import numpy as np 
import folium
from folium import plugins
import streamlit as st
from streamlit_folium import st_folium
from geopy.distance import geodesic
# import FAISS
# import torch

"""LLM Blocks"""

load_dotenv()
my_api_key = os.getenv("GOOGLE_API_KEY")


## LLM call 
llm = GoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=my_api_key)

## dataframe agent 
data_dir = 'data/JEJU_MCT_DATA_v2.csv'
df = pd.read_csv(data_dir,encoding='cp949')


## Data Frame agent on Gemini Engine 
agent = create_pandas_dataframe_agent(
    llm=llm,                           
    df=df,                             
    verbose=True,                      
    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, 
    output_parser = StrOutputParser(),
    prompt = agent_inst,
    allow_dangerous_code=True 
)

# RAG 
# device settings 
# # device = "cuda" if torch.cuda.is_available() else "cpu"
# model_name = "jhgan/ko-sroberta-multitask"
# tokenizer = AutoTokenizer.from_pretrained(model_name)
# embedding_model = AutoModel.from_pretrained(model_name).to(device)

# # embedding func
# def embed_text(text):
#     # í† í¬ë‚˜ì´ì €ì˜ ì¶œë ¥ë„ GPUë¡œ ì´ë™
#     inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)
#     with torch.no_grad():
#         # ëª¨ë¸ì˜ ì¶œë ¥ì„ GPUì—ì„œ ì—°ì‚°í•˜ê³ , í•„ìš”í•œ ë¶€ë¶„ì„ ê°€ì ¸ì˜´
#         embeddings = embedding_model(**inputs).last_hidden_state.mean(dim=1)
#     return embeddings.squeeze().cpu().numpy()  # ê²°ê³¼ë¥¼ CPUë¡œ ì´ë™í•˜ê³  numpy ë°°ì—´ë¡œ ë³€í™˜

# def generate_response_with_faiss(
#     question, df, embeddings, model, embed_text, 
#     time, local_choice, index_path=os.path.join(module_path, 'faiss_index.index'), 
#     max_count=10, k=3, print_prompt=True):
#     return None

import folium
from folium import plugins
import streamlit as st
from streamlit_folium import st_folium
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

import streamlit as st
import folium
from streamlit_folium import st_folium
import pandas as pd
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
import numpy as np

### ì—¬ê¸° ë³€ê²½
### ì„ë² ë”©, retriever, metadata ë“± ì¶”ê°€í•´ì•¼í•¨

def load_faiss_and_search(query, k=1):
    """FAISS DBì—ì„œ ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë§›ì§‘ ê²€ìƒ‰"""
    try:
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        embeddings = HuggingFaceEmbeddings(
            model_name="jhgan/ko-sroberta-multitask",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        # FAISS ë¡œë“œ
        db = FAISS.load_local(
            "faiss_db", 
            embeddings, 
            allow_dangerous_deserialization=True
        )
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        search_query = f"{query} {st.session_state.get('mbti', '')}"
        docs_with_scores = db.similarity_search_with_score(search_query, k=k)
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        search_results = []
        for doc, score in docs_with_scores:
            metadata = doc.metadata
            
            # ìœ„ë„, ê²½ë„ ê°’ì´ nanì¸ ê²½ìš° ì²˜ë¦¬
            try:
                search_results = [{'idx': 77, 'ìœ„ë„': 33.2455473, 'ê²½ë„': 126.5644088}, {'idx': 4, 'ìœ„ë„': 33.3700283, 'ê²½ë„': 126.2392054}, {'idx': 106, 'ìœ„ë„': 33.3189962, 'ê²½ë„': 126.3456767}]
                # lat = float(metadata['ìœ„ë„']) if pd.notna(metadata['ìœ„ë„']) else np.nan
                # lng = float(metadata['ê²½ë„']) if pd.notna(metadata['ê²½ë„']) else np.nan
                
                # search_results.append({
                #     'index': metadata.get('index', None),  # indexê°€ ì—†ëŠ” ê²½ìš° None ë°˜í™˜
                #     'ìœ„ë„': lat,
                #     'ê²½ë„': lng,
                #     'similarity_score': score
                # })
            except (ValueError, TypeError):
                search_results = [{'idx': 77, 'ìœ„ë„': 33.2455473, 'ê²½ë„': 126.5644088}, {'idx': 4, 'ìœ„ë„': 33.3700283, 'ê²½ë„': 126.2392054}, {'idx': 106, 'ìœ„ë„': 33.3189962, 'ê²½ë„': 126.3456767}]

                # ë³€í™˜ ë¶ˆê°€ëŠ¥í•œ ê°’ì´ ìˆëŠ” ê²½ìš°
                # search_results.append({
                #     'index': metadata.get('index', None),
                #     'ìœ„ë„': np.nan,
                #     'ê²½ë„': np.nan,
                #     'similarity_score': score
                # })


        
        return search_results
        
    except Exception as e:
        st.error(f"FAISS ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def get_restaurant_details(search_results, restaurants_df):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŒì‹ì  ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    try:
        restaurants_data = []
        for result in search_results:
            restaurant = restaurants_df.iloc[result['idx']]
            restaurants_data.append({
                'ìŒì‹ì ëª…': restaurant['ìŒì‹ì ëª…'],
                # 'ì£¼ì†Œ': restaurant['ì£¼ì†Œ'],
                'ìœ„ë„': result['ìœ„ë„'],
                'ê²½ë„': result['ê²½ë„'],
                # 'similarity_score': result['similarity_score']
            })
        print(restaurants_data)
        return pd.DataFrame(restaurants_data)

    except Exception as e:
        st.error(f"ìŒì‹ì  ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def find_nearby_tourist_spots(restaurant_row, tourist_spots_df, n=2):
    """ìŒì‹ì  ê·¼ì²˜ì˜ ê´€ê´‘ì§€ ì°¾ê¸°"""
    try:
        # ìŒì‹ì  ì¢Œí‘œê°€ NaNì¸ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        if pd.isna(restaurant_row['ìœ„ë„']) or pd.isna(restaurant_row['ê²½ë„']):
            return []

        # ìŒì‹ì  ì¢Œí‘œ
        restaurant_coords = (restaurant_row['ìœ„ë„'], restaurant_row['ê²½ë„'])
        
        # ê° ê´€ê´‘ì§€ì™€ì˜ ê±°ë¦¬ ê³„ì‚°
        distances = []
        for _, tourist in tourist_spots_df.iterrows():
            # ê´€ê´‘ì§€ ì¢Œí‘œê°€ NaNì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
            if pd.isna(tourist['ìœ„ë„']) or pd.isna(tourist['ê²½ë„']):
                continue
                
            try:
                tourist_coords = (tourist['ìœ„ë„'], tourist['ê²½ë„'])
                distance = geodesic(restaurant_coords, tourist_coords).kilometers
                
                distances.append({
                    'ê´€ê´‘ì§€ëª…': tourist['ê´€ê´‘ì§€ëª…'],
                    # 'ì£¼ì†Œ': tourist['ì£¼ì†Œ'],
                    'ìœ„ë„': tourist['ìœ„ë„'],
                    'ê²½ë„': tourist['ê²½ë„'],
                    'ê±°ë¦¬': distance
                })
            except Exception as e:
                # ê°œë³„ ê±°ë¦¬ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ í•´ë‹¹ ê´€ê´‘ì§€ ê±´ë„ˆë›°ê¸°
                print(f"ê±°ë¦¬ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ê´€ê´‘ì§€: {tourist['ê´€ê´‘ì§€ëª…']}): {str(e)}")
                continue
        
        # ê±°ë¦¬ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ nê°œ ì„ íƒ
        if distances:  # distancesê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì •ë ¬
            distances.sort(key=lambda x: x['ê±°ë¦¬'])
            return distances[:n]
        else:
            return []
        
    except Exception as e:
        st.error(f"ê´€ê´‘ì§€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def create_map_with_restaurants_and_tourists(restaurants_df, tourist_spots):
    """ë§›ì§‘ê³¼ ì£¼ë³€ ê´€ê´‘ì§€ë¥¼ í‘œì‹œí•˜ëŠ” ì§€ë„ ìƒì„±"""
    try:
        if restaurants_df is None or restaurants_df.empty:
            st.warning("ë§›ì§‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # NaNì´ ì•„ë‹Œ ì²« ë²ˆì§¸ ìœ„ì¹˜ë¥¼ ì°¾ì•„ ì¤‘ì‹¬ ì¢Œí‘œë¡œ ì„¤ì •
        valid_locations = restaurants_df[restaurants_df['ìœ„ë„'].notna() & restaurants_df['ê²½ë„'].notna()]
        if valid_locations.empty:
            st.warning("ìœ íš¨í•œ ìœ„ì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        center_lat = valid_locations.iloc[0]['ìœ„ë„']
        center_lng = valid_locations.iloc[0]['ê²½ë„']
        
        # ì§€ë„ ìƒì„±
        m = folium.Map(
            location=[center_lat, center_lng],
            zoom_start=14,
            tiles='CartoDB positron',
            width=800,
            height=600
        )
        
        # ë§›ì§‘ ë§ˆì»¤ ì¶”ê°€ (ë¹¨ê°„ìƒ‰)
        for idx, row in restaurants_df.iterrows():
            # NaN ê°’ í™•ì¸
            if pd.isna(row['ìœ„ë„']) or pd.isna(row['ê²½ë„']):
                continue
                
            popup_content = f"""
                <div style='width: 200px'>
                    <h4 style='margin: 0; padding: 5px 0;'>{row['ìŒì‹ì ëª…']}</h4>
                    <p style='margin: 5px 0;'>ì£¼ì†Œ: </p>
                </div>
            """
            
            folium.Marker(
                location=[row['ìœ„ë„'], row['ê²½ë„']],
                popup=folium.Popup(popup_content, max_width=300),
                icon=folium.Icon(color='red', icon='info-sign')
            ).add_to(m)
            
            # í•´ë‹¹ ë§›ì§‘ì˜ ì£¼ë³€ ê´€ê´‘ì§€ ë§ˆì»¤ ì¶”ê°€ (íŒŒë€ìƒ‰)
            if idx < len(tourist_spots):
                for tourist in tourist_spots[idx]:
                    # ê´€ê´‘ì§€ì˜ ìœ„ë„, ê²½ë„ NaN í™•ì¸
                    if pd.isna(tourist['ìœ„ë„']) or pd.isna(tourist['ê²½ë„']):
                        continue
                        
                    tourist_popup = f"""
                        <div style='width: 200px'>
                            <h4 style='margin: 0; padding: 5px 0;'>{tourist['ê´€ê´‘ì§€ëª…']}</h4>
                            <p style='margin: 5px 0;'>ì£¼ì†Œ: </p>
                            <p style='margin: 5px 0;'>ê±°ë¦¬: {tourist['ê±°ë¦¬']:.1f}km</p>
                        </div>
                    """
                    
                    folium.Marker(
                        location=[tourist['ìœ„ë„'], tourist['ê²½ë„']],
                        popup=folium.Popup(tourist_popup, max_width=300),
                        icon=folium.Icon(color='blue', icon='info-sign')
                    ).add_to(m)
        
        return m
        
    except Exception as e:
        print(e)

        st.error(f"ì§€ë„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def display_map_with_data(map_obj):
    """ìƒì„±ëœ ì§€ë„ë¥¼ ì•ˆì •ì ìœ¼ë¡œ í‘œì‹œ"""
    try:
        if map_obj:
            # ê³ ì •ëœ ì»¨í…Œì´ë„ˆì— ì§€ë„ í‘œì‹œ
            if 'map_container' not in st.session_state:
                st.session_state.map_container = st.empty()
                
            with st.session_state.map_container:
                # ì§€ë„ë¥¼ ê³ ì •ëœ í‚¤ì™€ í•¨ê»˜ í‘œì‹œ
                st_folium(
                    map_obj,
                    width=700,
                    height=500,
                    key="persistent_map",
                    returned_objects=[]
                )
                
    except Exception as e:
        st.error(f"ì§€ë„ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@st.cache_data
def create_cached_map(_restaurants_data, _tourist_spots):
    """ì§€ë„ ìƒì„±ì„ ìºì‹œí•˜ì—¬ ì¬ë Œë”ë§ ë°©ì§€"""
    return create_map_with_restaurants_and_tourists(_restaurants_data, _tourist_spots)

def format_restaurant_and_tourist_response(restaurants_df, tourist_spots):
    """ë§›ì§‘ê³¼ ê´€ê´‘ì§€ ì •ë³´ë¥¼ LLMì— ì „ë‹¬í•˜ê¸° ìœ„í•œ í¬ë§·íŒ…"""
    try:
        if restaurants_df is None or restaurants_df.empty:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë§›ì§‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        formatted_data = []
        for idx, row in restaurants_df.iterrows():
            restaurant_info = {
                "ì´ë¦„": row['ìŒì‹ì ëª…'],
                # "ì£¼ì†Œ": row['ì£¼ì†Œ'],
                # "ìœ ì‚¬ë„_ì ìˆ˜": float(row['similarity_score']),
                "ì£¼ë³€_ê´€ê´‘ì§€": [
                    {
                        "ì´ë¦„": tourist['ê´€ê´‘ì§€ëª…'],
                        # "ì£¼ì†Œ": tourist['ì£¼ì†Œ'],
                        "ê±°ë¦¬": f"{tourist['ê±°ë¦¬']:.1f}km"
                    }
                    for tourist in tourist_spots[idx]
                ]
            }
            formatted_data.append(restaurant_info)
            
        return formatted_data
        
    except Exception as e:
        return f"ì •ë³´ í¬ë§¤íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def generate_llm_response(query, formatted_data, user_mbti=None):
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ë§›ì§‘ê³¼ ê´€ê´‘ì§€ ì¶”ì²œ ì‘ë‹µ ìƒì„±"""
    try:
        prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: {query}

        ì•„ë˜ëŠ” ê²€ìƒ‰ëœ ë§›ì§‘ê³¼ ì£¼ë³€ ê´€ê´‘ì§€ ì •ë³´ì…ë‹ˆë‹¤:
        {formatted_data}

        {f'ì‚¬ìš©ìì˜ MBTIëŠ” {user_mbti}ì…ë‹ˆë‹¤.' if user_mbti else ''}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ìì—°ìŠ¤ëŸ¬ìš´ ë§›ì§‘ê³¼ ê´€ê´‘ì§€ ì¶”ì²œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

        1. ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í†¤ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        2. ê° ë§›ì§‘ì˜ ì¥ì ê³¼ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        3. ê° ë§›ì§‘ ê·¼ì²˜ì˜ ê´€ê´‘ì§€ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì†Œê°œí•´ì£¼ì„¸ìš”.
        4. ë§›ì§‘ê³¼ ê´€ê´‘ì§€ì˜ ìœ„ì¹˜ì  íŠ¹ì„±ì´ë‚˜ ì ‘ê·¼ì„±ì— ëŒ€í•´ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
        5. ì‚¬ìš©ìì˜ MBTIê°€ ìˆë‹¤ë©´, ê·¸ì— ë§ì¶˜ ì„¤ëª…ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.
        6. ë§›ì§‘ê³¼ ê´€ê´‘ì§€ë¥¼ í•¨ê»˜ ì¦ê¸°ëŠ” ì½”ìŠ¤ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.
        7. ì¦ê±°ìš´ ì—¬í–‰ì´ ë˜ê¸¸ ë°”ë¼ëŠ” ë©˜íŠ¸ë¡œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.

        ë‹µë³€ì—ì„œëŠ” ìœ„ë„/ê²½ë„ ì •ë³´ë‚˜ ìœ ì‚¬ë„ ì ìˆ˜ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”."""

        response = llm.invoke(input=prompt)
        return response
        
    except Exception as e:
        return f"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def process_recommendation(message):
    """ì¶”ì²œ ê´€ë ¨ ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜"""
    try:
        # ë°ì´í„°í”„ë ˆì„ ë¡œë“œ
        restaurants_df = pd.read_csv('ìŒì‹ì ìœ„ê²½ë„.csv')
        tourist_spots_df = pd.read_csv('ê´€ê´‘ì§€ìœ„ê²½ë„.csv')
        
        # 1. FAISS ê²€ìƒ‰
        search_results = load_faiss_and_search(message, k=3)
        if not search_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹í•˜ëŠ” ë§›ì§‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None, None
            
        # 2. ìŒì‹ì  ìƒì„¸ ì •ë³´ ì¡°íšŒ
        restaurants_data = get_restaurant_details(search_results, restaurants_df)
        if restaurants_data is None:
            return "ìŒì‹ì  ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", None, None
            
        # 3. ì£¼ë³€ ê´€ê´‘ì§€ ì°¾ê¸°
        tourist_spots = []
        for _, restaurant in restaurants_data.iterrows():
            nearby_spots = find_nearby_tourist_spots(restaurant, tourist_spots_df)
            tourist_spots.append(nearby_spots)
            
        # 4. ì§€ë„ ìƒì„±
        map_obj = create_map_with_restaurants_and_tourists(restaurants_data, tourist_spots)
        
        # 5. LLM ì‘ë‹µìš© ë°ì´í„° ì¤€ë¹„
        formatted_data = format_restaurant_and_tourist_response(restaurants_data, tourist_spots)
        
        # 6. LLM ì‘ë‹µ ìƒì„±
        user_mbti = st.session_state.get('mbti', None)
        response = generate_llm_response(message, formatted_data, user_mbti)
        
        return response, restaurants_data, tourist_spots
        
    except Exception as e:
        print(f"Error in recommendation process: {e}")
        return f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", None, None

"""Fuctions for JMT app"""

## MBTI validate
def validate_mbti(mbti):
    # input length 
    if len(mbti) != 4:
        return False
    
    # input value
    if mbti[0] not in {"E", "I"}: 
        return False
    if mbti[1] not in {"N", "S"}: 
        return False
    if mbti[2] not in {"F", "T"}:
        return False
    if mbti[3] not in {"P", "J"}: 
        return False

    return True  

def clear_chat_history():
    st.session_state.memory = ConversationBufferMemory()
    st.session_state.messages = [{"role": "assistant", "content": "ì œì£¼ë„ë¥¼ ì—¬í–‰í•˜ê¸° ë”± ì¢‹ì€ ë‚ ì”¨ë„¤ìš” ğŸ˜"}]
