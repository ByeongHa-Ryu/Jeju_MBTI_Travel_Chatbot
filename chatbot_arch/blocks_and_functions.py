from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain.agents.agent_types import AgentType
from langchain_core.output_parsers import StrOutputParser,JsonOutputParser
from langchain.memory import ConversationBufferMemory
from langchain_google_genai import GoogleGenerativeAI # type: ignore
from dotenv import load_dotenv
import os
from prompts import cls_llm_inst
import pandas as pd
from prompts import * 
import streamlit as st
from transformers import AutoTokenizer, AutoModel
import numpy as np 
import folium
from folium import plugins
import streamlit as st
from streamlit_folium import st_folium
# import FAISS
# import torch

"""LLM Blocks"""

load_dotenv()
my_api_key = os.getenv("GOOGLE_API_KEY")


## LLM call 
llm = GoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=my_api_key)

## dataframe agent 
data_dir = 'data/JEJU_MCT_DATA_v2.csv'
df = pd.read_csv(data_dir,encoding='cp949')


## Data Frame agent on Gemini Engine 
agent = create_pandas_dataframe_agent(
    llm=llm,                           
    df=df,                             
    verbose=True,                      
    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, 
    output_parser = StrOutputParser(),
    prompt = agent_inst,
    allow_dangerous_code=True 
)

## RAG 
#device settings 
# device = "cuda" if torch.cuda.is_available() else "cpu"
model_name = "jhgan/ko-sroberta-multitask"
tokenizer = AutoTokenizer.from_pretrained(model_name)
# embedding_model = AutoModel.from_pretrained(model_name).to(device)

# # embedding func
# def embed_text(text):
#     # í† í¬ë‚˜ì´ì €ì˜ ì¶œë ¥ë„ GPUë¡œ ì´ë™
#     inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)
#     with torch.no_grad():
#         # ëª¨ë¸ì˜ ì¶œë ¥ì„ GPUì—ì„œ ì—°ì‚°í•˜ê³ , í•„ìš”í•œ ë¶€ë¶„ì„ ê°€ì ¸ì˜´
#         embeddings = embedding_model(**inputs).last_hidden_state.mean(dim=1)
#     return embeddings.squeeze().cpu().numpy()  # ê²°ê³¼ë¥¼ CPUë¡œ ì´ë™í•˜ê³  numpy ë°°ì—´ë¡œ ë³€í™˜

# def generate_response_with_faiss(
#     question, df, embeddings, model, embed_text, 
#     time, local_choice, index_path=os.path.join(module_path, 'faiss_index.index'), 
#     max_count=10, k=3, print_prompt=True):
#     return None

import folium
from folium import plugins
import streamlit as st
from streamlit_folium import st_folium
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

import streamlit as st
import folium
from streamlit_folium import st_folium
import pandas as pd
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS

### ì—¬ê¸° ë³€ê²½
### ì„ë² ë”©, retriever, metadata ë“± ì¶”ê°€í•´ì•¼í•¨

def load_faiss_and_search(query, k=3):
    """FAISS DBì—ì„œ ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë§›ì§‘ ê²€ìƒ‰"""
    try:
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        embeddings = HuggingFaceEmbeddings(
            model_name="jhgan/ko-sroberta-multitask",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        # FAISS ë¡œë“œ
        db = FAISS.load_local(
            "faiss_db", 
            embeddings, 
            allow_dangerous_deserialization=True
        )
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        search_query = f"{query} {st.session_state.get('mbti', '')}"
        
        # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
        docs = db.similarity_search_with_score(search_query, k=k)
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        restaurants_data = []
        for doc, score in docs:
            metadata = doc.metadata
            restaurants_data.append({
                'ìŒì‹ì ëª…': metadata['ìŒì‹ì ëª…'],
                'ì£¼ì†Œ': metadata['ì£¼ì†Œ'],
                'ìœ„ë„': float(metadata['ìœ„ë„']),
                'ê²½ë„': float(metadata['ê²½ë„']),
                'similarity_score': score
            })
        
        return pd.DataFrame(restaurants_data)
    
    except Exception as e:
        st.error(f"FAISS ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def create_map_with_restaurants(restaurants_df):
    """ë§›ì§‘ ì •ë³´ë¡œ ì§€ë„ ìƒì„±"""
    try:
        if restaurants_df is None or restaurants_df.empty:
            st.warning("ë§›ì§‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        # ì²« ë²ˆì§¸ ë§›ì§‘ ìœ„ì¹˜ë¡œ ì¤‘ì‹¬ ì¢Œí‘œ ì„¤ì •
        center_lat = restaurants_df.iloc[0]['ìœ„ë„']
        center_lng = restaurants_df.iloc[0]['ê²½ë„']
        
        # ì§€ë„ ìƒì„±
        m = folium.Map(
            location=[center_lat, center_lng],
            zoom_start=14,  # ì¤Œ ë ˆë²¨ ì¡°ì •
            tiles='CartoDB positron',
            width=800,  # ì§€ë„ í¬ê¸° ëª…ì‹œ
            height=600
        )
        
        # ë§›ì§‘ ë§ˆì»¤ ì¶”ê°€
        for idx, row in restaurants_df.iterrows():
            popup_content = f"""
                <div style='width: 200px'>
                    <h4 style='margin: 0; padding: 5px 0;'>{row['ìŒì‹ì ëª…']}</h4>
                    <p style='margin: 5px 0;'>ì£¼ì†Œ: {row['ì£¼ì†Œ']}</p>
                </div>
            """
            
            folium.Marker(
                location=[row['ìœ„ë„'], row['ê²½ë„']],
                popup=folium.Popup(popup_content, max_width=300),
                icon=folium.Icon(color='red', icon='info-sign')
            ).add_to(m)
        
        return m
    except Exception as e:
        st.error(f"ì§€ë„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def display_map(restaurants_df):
    """ì§€ë„ í‘œì‹œ í•¨ìˆ˜"""
    try:
        # ìƒíƒœ ì´ˆê¸°í™”
        if 'map_data' not in st.session_state:
            st.session_state.map_data = None
        
        if 'current_restaurants' not in st.session_state:
            st.session_state.current_restaurants = None
            
        # ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“¤ì–´ì™”ì„ ë•Œë§Œ ì§€ë„ ì—…ë°ì´íŠ¸
        if (st.session_state.current_restaurants is None or 
            not restaurants_df.equals(st.session_state.current_restaurants)):
            
            st.session_state.current_restaurants = restaurants_df.copy()
            
            # ì²« ë²ˆì§¸ ë§›ì§‘ ìœ„ì¹˜ë¡œ ì¤‘ì‹¬ ì¢Œí‘œ ì„¤ì •
            center_lat = restaurants_df.iloc[0]['ìœ„ë„']
            center_lng = restaurants_df.iloc[0]['ê²½ë„']
            
            # ì§€ë„ ìƒì„±
            m = folium.Map(
                location=[center_lat, center_lng],
                zoom_start=14,
                tiles='CartoDB positron',
            )
            
            # ë§›ì§‘ ë§ˆì»¤ ì¶”ê°€
            for idx, row in restaurants_df.iterrows():
                popup_content = f"""
                    <div style='width: 200px'>
                        <h4 style='margin: 0; padding: 5px 0;'>{row['ìŒì‹ì ëª…']}</h4>
                        <p style='margin: 5px 0;'>ì£¼ì†Œ: {row['ì£¼ì†Œ']}</p>
                    </div>
                """
                
                folium.Marker(
                    location=[row['ìœ„ë„'], row['ê²½ë„']],
                    popup=folium.Popup(popup_content, max_width=300),
                    icon=folium.Icon(color='red', icon='info-sign')
                ).add_to(m)
            
            # ì§€ë„ë¥¼ ê³ ì •ëœ ì»¨í…Œì´ë„ˆì— í‘œì‹œ
            map_container = st.empty()
            with map_container:
                st.session_state.map_data = st_folium(
                    m,
                    width=700,
                    height=500,
                    returned_objects=["last_clicked"],
                    key="stable_map"
                )
        
        return st.session_state.map_data
        
    except Exception as e:
        st.error(f"ì§€ë„ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def format_restaurant_response(restaurants_df):
    """ë§›ì§‘ ì •ë³´ë¥¼ LLMì— ì „ë‹¬í•˜ê¸° ìœ„í•œ í¬ë§·íŒ…"""
    try:
        if restaurants_df is None or restaurants_df.empty:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë§›ì§‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        # LLMì— ì „ë‹¬í•  ë§›ì§‘ ì •ë³´ êµ¬ì„±
        restaurants_info = []
        for idx, row in restaurants_df.iterrows():
            restaurant_info = {
                "ì´ë¦„": row['ìŒì‹ì ëª…'],
                "ì£¼ì†Œ": row['ì£¼ì†Œ'],
                "ìœ ì‚¬ë„_ì ìˆ˜": float(row['similarity_score'])  # ìœ ì‚¬ë„ ì ìˆ˜ ì¶”ê°€
            }
            restaurants_info.append(restaurant_info)
            
        return restaurants_info
        
    except Exception as e:
        return f"ë§›ì§‘ ì •ë³´ í¬ë§¤íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def generate_llm_response(query, restaurants_info, user_mbti=None):
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ë§›ì§‘ ì¶”ì²œ ì‘ë‹µ ìƒì„±"""
    try:
        # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: {query}

    ì•„ë˜ëŠ” ê²€ìƒ‰ëœ ë§›ì§‘ ì •ë³´ì…ë‹ˆë‹¤:
        {restaurants_info}

        {f'ì‚¬ìš©ìì˜ MBTIëŠ” {user_mbti}ì…ë‹ˆë‹¤.' if user_mbti else ''}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ìì—°ìŠ¤ëŸ¬ìš´ ë§›ì§‘ ì¶”ì²œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

        1. ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í†¤ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        2. ê° ë§›ì§‘ì˜ ì¥ì ê³¼ íŠ¹ì§•ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        3. ë§›ì§‘ë“¤ì˜ ìœ„ì¹˜ì  íŠ¹ì„±ì´ë‚˜ ì ‘ê·¼ì„±ì— ëŒ€í•´ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
        4. ì‚¬ìš©ìì˜ MBTIê°€ ìˆë‹¤ë©´, ê·¸ì— ë§ì¶˜ ë§›ì§‘ ì„¤ëª…ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.
        5. ë§ˆì§€ë§‰ì—ëŠ” ì¦ê±°ìš´ ì‹ì‚¬ê°€ ë˜ê¸¸ ë°”ë¼ëŠ” ë©˜íŠ¸ë¡œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.

        ë‹µë³€ì—ì„œëŠ” ìœ„ë„/ê²½ë„ ì •ë³´ë‚˜ ìœ ì‚¬ë„ ì ìˆ˜ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”."""

        # LLMìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        response = llm.invoke(input=prompt)
        return response
        
    except Exception as e:
        return f"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


"""Fuctions for JMT app"""

## MBTI validate
def validate_mbti(mbti):
    # input length 
    if len(mbti) != 4:
        return False
    
    # input value
    if mbti[0] not in {"E", "I"}: 
        return False
    if mbti[1] not in {"N", "S"}: 
        return False
    if mbti[2] not in {"F", "T"}:
        return False
    if mbti[3] not in {"P", "J"}: 
        return False

    return True  

def clear_chat_history():
    st.session_state.memory = ConversationBufferMemory()
    st.session_state.messages = [{"role": "assistant", "content": "ì œì£¼ë„ë¥¼ ì—¬í–‰í•˜ê¸° ë”± ì¢‹ì€ ë‚ ì”¨ë„¤ìš” ğŸ˜"}]
