import os
from contextlib import redirect_stdout
import io
from prompts import *
from blocks_and_functions import *
import streamlit as st
import folium
from streamlit_folium import folium_static
import google.generativeai as genai
import json
import re
from langchain.vectorstores import FAISS
from streamlit_folium import st_folium
import random
from langchain_community.embeddings import HuggingFaceEmbeddings


embeddings = HuggingFaceEmbeddings(
    model_name="jhgan/ko-sroberta-multitask",  # í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)

def Callout(message,memory):
    try:
        # Query classification 
        classification_response = llm.invoke(input=cls_llm_inst.format(input_query=message,memory = memory))

        if "ë¶„ì„ ê´€ë ¨" in classification_response:
            print(message, ': cls ì„ì‹œ printë¬¸ : ë¶„ì„')
            
            # process for sending Verbose of the agent to the post processor 
            f = io.StringIO()
            with redirect_stdout(f):
                analysis_result = agent.invoke(
                    input=message)
                
            verbose_output = f.getvalue()
            #print(verbose_output)
            
            # post processor 
            final_response = llm.invoke(
                input=post_agent_inst.format(
                    input_query = message,
                    verbose_output = verbose_output,
                    analysis_result = analysis_result
                    )
            )
        
        ### ì—¬ê¸° ë³€ê²½
        elif "ì¶”ì²œ ê´€ë ¨" in classification_response:
            print('cls ì„ì‹œ printë¬¸ : ì¶”ì²œ')
            
            try:
                # FAISSë¡œ ë§›ì§‘ ê²€ìƒ‰
                restaurants_df = load_faiss_and_search(message, k=3)
                
                if restaurants_df is not None and not restaurants_df.empty:
                    # ë§›ì§‘ ì •ë³´ êµ¬ì„±
                    restaurants_info = format_restaurant_response(restaurants_df)
                    
                    # LLM ì‘ë‹µ ìƒì„±
                    user_mbti = st.session_state.get('mbti', None)
                    final_response = generate_llm_response(message, restaurants_info, user_mbti)
                    
                    # ì§€ë„ í‘œì‹œ
                    title_container = st.empty()
                    title_container.subheader("ğŸ—ºï¸ ì¶”ì²œ ë§›ì§‘ ìœ„ì¹˜")
                    display_map(restaurants_df)
                    
                else:
                    final_response = "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹í•˜ëŠ” ë§›ì§‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
            except Exception as e:
                final_response = f"ë§›ì§‘ ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                print(f"Error in recommendation: {e}")
        

        
        
        else:
            print('cls ì„ì‹œ printë¬¸ : ì¼ë°˜ ì§ˆë¬¸')
            final_response = llm.invoke(
                input=main_persona.format(input_query=message,memory = memory)
            )

    except Exception as e:
        final_response = f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    return final_response

